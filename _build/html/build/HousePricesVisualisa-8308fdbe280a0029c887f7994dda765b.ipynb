{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices\n",
    "\n",
    "This project involved building an interactive web app, using Shiny for Python, to display house prices in England and Wales, adding a Choropleth layer to visualise the differences by region. The aim was to demonstrate the Shiny software and investigate trends in house prices over time and across different regions of England and Wales.\n",
    "\n",
    "##### About the data\n",
    "\n",
    "Write description here of how I got the data and how it's created/published.\n",
    "\n",
    "##### Initial planning\n",
    "\n",
    "- What granularity to use? e.g. county, town, postcode\n",
    "    - The dataset contains the postcode of each property, and every postcode has a clearly defined area, which should be available online\n",
    "    - The whole postcode is likely too granular - using the area code or district code should be a good compromise\n",
    "- How to aggregate price paid by area?\n",
    "    - Min, Max, Median, Mean\n",
    "    - Allow user to choose which statistic to show on the map\n",
    "    - Could also compare these summary statistics between points in time, which would highlight the areas which have seen the greatest changes in price over time\n",
    "\n",
    "##### Preparing the data\n",
    "\n",
    "Loading the CSV file into a MySQL database.\n",
    "\n",
    "~~~~sql\n",
    "DROP DATABASE IF EXISTS `houseprices`;\n",
    "CREATE DATABASE `houseprices`;\n",
    "USE `houseprices`;\n",
    "\n",
    "CREATE TABLE `pricepaid` (\n",
    "`unique_id` VARCHAR(100),\n",
    "`price_paid` DECIMAL,\n",
    "`deed_date` DATE,\n",
    "`postcode` VARCHAR(8),\n",
    "`property_type` VARCHAR(1),\n",
    "`new_build` VARCHAR(1),\n",
    "`estate_type` VARCHAR(1),\n",
    "`saon` VARCHAR(50),\n",
    "`paon` VARCHAR(50),\n",
    "`street` VARCHAR(50),\n",
    "`locality` VARCHAR(50),\n",
    "`town` VARCHAR(50),\n",
    "`district` VARCHAR(50),\n",
    "`county` VARCHAR(50),\n",
    "`transaction_category` VARCHAR(1),\n",
    "`linked_data_uri` VARCHAR(1),\n",
    "PRIMARY KEY (unique_id)\n",
    ");\n",
    "\n",
    "SET GLOBAL local_infile=ON;\n",
    "SET autocommit=0;\n",
    "SET unique_checks=1;\n",
    "SET foreign_key_checks=0;\n",
    "\n",
    "LOAD DATA LOW_PRIORITY \n",
    "LOCAL INFILE 'Path/To/Project/pricepaid.csv'\n",
    "INTO TABLE pricepaid \n",
    "CHARACTER SET armscii8\n",
    "FIELDS TERMINATED BY ','\n",
    "ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\n' \n",
    "(`unique_id`,`price_paid`,`deed_date`,`postcode`,`property_type`,`new_build`,`estate_type`,`saon`,`paon`,`street`,`locality`,`town`,`district`,`county`,`transaction_category`,`linked_data_uri`);\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had originally planned to use the full dataset in my Shiny app, however the full table is ~5GB in size with ~29m rows. I chose to get around this by sampling the dataset. Taking a simple random sample of the data would mean that the number of samples from each area would be proportional to the population of that area, so to ensure that each area had an equal number of samples I would use stratified sampling instead.\n",
    "\n",
    "I needed to choose a level of granularity to which to stratify the data. A UK postcode is made up of 2 parts, the outward code (first part) and inward code (second part), separated by a space. The outward code consists of the postcode area (either 1 or 2 letters) followed by the postcode district (usually 1 or 2 digits). For example, in the postcode PO16 7GZ, PO16 is the outward code (or outcode), PO is the area and 16 is the district.\n",
    "\n",
    "OutCode and PostcodeArea were added as generated columns to the pricepaid table, along with a Year column and a YearBin column.\n",
    "\n",
    "~~~~sql\n",
    "ALTER TABLE pricepaid ADD COLUMN OutCode VARCHAR(4) GENERATED ALWAYS AS substr(postcode, 1, locate(' ', postcode) - 1) STORED;\n",
    "ALTER TABLE pricepaid ADD COLUMN PostcodeArea VARCHAR(3) GENERATED ALWAYS AS regexp_replace(OutCode, '[0-9]+', '') STORED;\n",
    "ALTER TABLE pricepaid ADD COLUMN Year INT GENERATED ALWAYS AS year(cast(deed_date as date)) STORED;\n",
    "ALTER TABLE pricepaid ADD COLUMN YearBin VARCHAR(4) GENERATED ALWAYS AS case when (Year < 2005) then '1995 - 2004' when (Year < 2015) then '2005 - 2014' else '2015 +' end STORED;\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an index on Outcode and YearBin to speed up the stratified sample query.\n",
    "\n",
    "~~~~sql\n",
    "CREATE INDEX OutcodeYearBinIndex ON pricepaid (Outcode, YearBin);\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a stratified sample of 100 observations for each distinct OutCode and YearBin.\n",
    "\n",
    "~~~~sql\n",
    "SELECT t.* FROM\n",
    "(SELECT pp.*, ROW_NUMBER() OVER (PARTITION BY OutCode, YearBin ORDER BY RAND()) AS SeqNum\n",
    "FROM pricepaid pp) t\n",
    "WHERE t.SeqNum <= 100\n",
    "INTO LOCAL OUTFILE '/Path/To/Project/pricepaidsample.csv'\n",
    "FIELDS TERMINATED BY ','\n",
    "ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\n';\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming and aggregating the data\n",
    "\n",
    "Before the data can be used in the Shiny app, it needs to be aggregated by area. Doing this outside the Shiny app and instead reading the aggregated data directly improves the performance of the app.\n",
    "\n",
    "Additionally, a GeoJSON file needed to be created so that the Shiny app knows where the boundaries of each postcode area are.\n",
    "\n",
    "First, the sample CSV is read into a Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "### Load data\n",
    "appDir = Path(__file__).parent\n",
    "print(\"Importing data...\")\n",
    "dataset = pd.read_csv(appDir / \"pricepaidsample.csv\", delimiter='\\t', header=0, encoding=\"utf-8\")\n",
    "# remove missing postcodes\n",
    "dataset = dataset[~dataset['postcode'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A folder containing a GeoJSON file with the polygon coordinates of each Outcode was downloaded online. This is combined into a single GeoJSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### Get polygon coordinates (GeoJSON) of each PostcodeArea\n",
    "geojsonDir = appDir / 'districts'\n",
    "# combine all PostcodeArea datasets, one for each PostcodeArea\n",
    "geojsonDict = {}\n",
    "print(\"Importing geojson files...\")\n",
    "for file in geojsonDir.glob('*.geojson'):\n",
    "    with open(file, 'r') as f:\n",
    "        geojsonDict[str(file).split('\\\\')[-1][:-8]] = json.load(f)\n",
    "# add id string to link to summary data\n",
    "for key in geojsonDict.keys():\n",
    "    geojsonDict[key]['features'][0]['id'] = key\n",
    "# changing format of geojsonDict to meet required format for Choropleth function\n",
    "geojsonList = []\n",
    "uniqueOutcodes = dataset['Outcode'].unique().tolist()\n",
    "for outcode in geojsonDict.keys():\n",
    "    features = geojsonDict[outcode]['features']\n",
    "    if outcode in uniqueOutcodes:\n",
    "        geojsonList.append(features[0])\n",
    "geojsonDict = {}\n",
    "geojsonDict['type'] = 'FeatureCollection'\n",
    "geojsonDict['features'] = geojsonList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics (mean, median, min, max) of the price paid were calculated for each Outcode and YearBin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "### aggregate data import by Outcode and YearBin\n",
    "summary = dataset.groupby([\"Outcode\", \"YearBin\"])['price_paid'].agg(['min', 'max', 'mean', 'median']).reset_index()\n",
    "# make sure there is a row for every Outcode and YearBin - set aggregate values to null if missing\n",
    "uniqueYearBins = dataset['YearBin'].unique().tolist()\n",
    "crossJoin = list(itertools.product(uniqueOutcodes, uniqueYearBins))\n",
    "crossJoin = pd.DataFrame(crossJoin, columns=[\"Outcode\", \"YearBin\"])\n",
    "summary = pd.merge(crossJoin, summary, how=\"left\", on=[\"Outcode\", \"YearBin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the final step in the data preparation, the GeoJSON file and summary dataset were exported to the folder so that they can be read into the Shiny app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as geojson dictionary as json file\n",
    "with open(appDir / 'OutcodeCoordinates.json', 'w') as fp:\n",
    "    json.dump(geojsonDict, fp)\n",
    "\n",
    "# export summary dataframe as csv\n",
    "summary.to_csv(appDir / 'summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the Shiny app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app.py program of the Shiny app consists of 3 main parts:\n",
    "\n",
    "- importing the data\n",
    "- building the HTML interface\n",
    "- defining a server function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from ipyleaflet import Map, Choropleth\n",
    "from shiny import App, Inputs, Outputs, Session, ui, reactive\n",
    "from shinywidgets import output_widget, render_widget\n",
    "from branca.colormap import linear\n",
    "\n",
    "### Load data\n",
    "appDir = Path(__file__).parent\n",
    "with open(appDir / 'OutcodeCoordinates.json', 'r') as f:\n",
    "    outcodeCoordinates = json.load(f)\n",
    "summary = pd.read_csv(appDir / 'summary.csv')\n",
    "yearBins = list(summary['YearBin'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Building the HTML interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nest Python functions to build an HTML interface\n",
    "app_ui = ui.page_fillable( \n",
    "    # Layout the UI with Layout Functions\n",
    "    # Add Inputs with ui.input_*() functions \n",
    "    # Add Outputs with ui.output_*() functions\n",
    "    ui.layout_sidebar(\n",
    "        ui.sidebar(\n",
    "            ui.input_checkbox_group('yearBin', \"Time Period\", yearBins),\n",
    "            ui.input_select('statistic', \"House Price Summary Statistic\", ['mean', 'median', 'min', 'max'], selected='mean', multiple=False),\n",
    "            ui.input_switch(\"switch\", \"Compare Summary Statistic between Time Periods\", False)\n",
    "        ),\n",
    "        ui.card(\n",
    "            output_widget(\"map\", width=\"auto\", height=\"auto\")\n",
    "        )\n",
    "    ),\n",
    "    title=\"UK House Prices Visualisation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Defining a server function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define server\n",
    "def server(input: Inputs, output: Outputs, session: Session):\n",
    "    # function to filter the summary dataset and return a lookup dictionary with a key for each Outcode\n",
    "    @reactive.calc\n",
    "    def createChoroData():\n",
    "\n",
    "        # select all time periods if none are selected\n",
    "        if input.yearBin() == tuple():\n",
    "            filter = yearBins\n",
    "        else:\n",
    "            filter = list(input.yearBin())\n",
    "\n",
    "        # logic for comparing summary stastics between time periods\n",
    "        if input.switch():\n",
    "            minYearBin = filter[0]\n",
    "            maxYearBin = filter[-1]\n",
    "            dfMin = summary[summary['YearBin'] == minYearBin][['Outcode', input.statistic()]]\n",
    "            dfMax = summary[summary['YearBin'] == maxYearBin][['Outcode', input.statistic()]]\n",
    "            df = pd.merge(dfMin, dfMax, how=\"inner\", on=\"Outcode\")\n",
    "            df['diff'] = df[input.statistic() + '_y'] - df[input.statistic() + '_x']\n",
    "            df = df.set_index('Outcode')\n",
    "            df['decile'] = pd.qcut(df['diff'], 10, labels=False)\n",
    "            return df['decile'].to_dict()\n",
    "        # if not comparing time periods then just show summary statistic\n",
    "        else:\n",
    "            df = summary[summary['YearBin'].isin(filter)].set_index('Outcode')\n",
    "            df['decile'] = pd.qcut(df[input.statistic()], 10, labels=False)\n",
    "            return df['decile'].to_dict()\n",
    "\n",
    "    ### For each output, define a function that generates the output\n",
    "    @render_widget  \n",
    "    def map():\n",
    "        # create a Map object and add a Choropleth layer to it\n",
    "        m = Map(center=(54.00366, -2.547855), zoom=5.5)\n",
    "\n",
    "        layer = Choropleth(\n",
    "                    geo_data=outcodeCoordinates,\n",
    "                    choro_data=createChoroData(),\n",
    "                    key_on='id',\n",
    "                    colormap=linear.viridis,\n",
    "                    border_color='black',\n",
    "                    style={'fillOpacity': 0.8, 'dashArray': '5, 5'}\n",
    "                )\n",
    "        \n",
    "        m.add(layer)\n",
    "\n",
    "        return m\n",
    "\n",
    "# Call App() to combine app_ui and server() into an interactive app\n",
    "app = App(app_ui, server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instead just loaded pre-summarised data into the app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
